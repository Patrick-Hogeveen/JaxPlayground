{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad, jit, vmap\n",
    "from jax import random\n",
    "import jax.scipy as jsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to init layer of size nxm with key and scale\n",
    "def random_layer_params(m,n,key,scale=1e-2):\n",
    "    w_key, b_key = random.split(key)\n",
    "    return scale * random.normal(w_key, (n, m)), scale*random.normal(b_key, (n,))\n",
    "\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m,n,k) for m,n,k in zip(sizes[:-1], sizes[1:], keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [484, 512, 512, 47]\n",
    "step_size = 0.01\n",
    "num_epochs = 20\n",
    "batch_size = 128\n",
    "n_targets = 47\n",
    "params = init_network_params(layer_sizes, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.scipy.special import logsumexp\n",
    "\n",
    "def relu(x):\n",
    "    return jnp.maximum(0,x)\n",
    "\n",
    "def predict(params2, kernel, image):\n",
    "    activations = image\n",
    "    activations = jsp.signal.convolve(activations.reshape(28,28), kernel, mode=\"valid\")\n",
    "    activations = activations.reshape(22*22).squeeze()\n",
    "    \n",
    "    \n",
    "    for w, b in params2[:-1]:\n",
    "        outputs = jnp.dot(w, activations) + b\n",
    "        activations = relu(outputs)\n",
    "\n",
    "    final_w, finals_b = params2[-1]\n",
    "    logits = jnp.dot(final_w, activations) + finals_b\n",
    "\n",
    "    return logits - logsumexp(logits)\n",
    "\n",
    "batched_predict = vmap(predict, in_axes=(None, None, 0))\n",
    "\n",
    "def loss2(params, window, images, targets):\n",
    "    preds = batched_predict(params, window, images)\n",
    "    ret = -jnp.mean(preds * targets)\n",
    "    return ret\n",
    "\n",
    "@jit\n",
    "def update(params, window, x , y):\n",
    "    grads = grad(loss2, (0,1))(params, window, x, y)\n",
    "\n",
    "    return (window - step_size * grads[1], [(w - step_size * dw, b - step_size * db)\n",
    "            for (w, b), (dw, db) in zip(params, grads[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    #creates one hot encoding of x of size k\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "def accuracy(params, window, images, targets):\n",
    "    target_class = jnp.argmax(targets, axis=1)\n",
    "    predicted_class = jnp.argmax(batched_predict(params, window, images), axis=1)\n",
    "    return jnp.mean(predicted_class == target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jax.tree_util import tree_map\n",
    "from torch.utils import data\n",
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "def numpy_collate(batch):\n",
    "    return tree_map(np.asarray, data.default_collate(batch))\n",
    "\n",
    "class NumpyLoader(data.DataLoader):\n",
    "  def __init__(self, dataset, batch_size=1,\n",
    "                shuffle=False, sampler=None,\n",
    "                batch_sampler=None, num_workers=0,\n",
    "                pin_memory=False, drop_last=False,\n",
    "                timeout=0, worker_init_fn=None):\n",
    "    super(self.__class__, self).__init__(dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        sampler=sampler,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=numpy_collate,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=drop_last,\n",
    "        timeout=timeout,\n",
    "        worker_init_fn=worker_init_fn)\n",
    "\n",
    "class FlattenAndCast(object):\n",
    "  def __call__(self, pic):\n",
    "    return np.ravel(np.array(pic, dtype=jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our dataset, using torch datasets\n",
    "mnist_dataset = EMNIST('/tmp/emnist/', split=\"balanced\", download=True, transform=FlattenAndCast())\n",
    "training_generator = NumpyLoader(mnist_dataset, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the full train dataset (for checking accuracy while training)\n",
    "train_images = np.array(mnist_dataset.train_data).reshape(len(mnist_dataset.train_data), -1)\n",
    "train_labels = one_hot(np.array(mnist_dataset.train_labels), n_targets)\n",
    "\n",
    "# Get full test dataset\n",
    "mnist_dataset_test = EMNIST('/tmp/emnist/', split=\"balanced\", download=True, train=False)\n",
    "test_images = jnp.array(mnist_dataset_test.test_data.numpy().reshape(len(mnist_dataset_test.test_data), -1), dtype=jnp.float32)\n",
    "test_labels = one_hot(np.array(mnist_dataset_test.test_labels), n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init \"network\"\n",
    "params2 = init_network_params(layer_sizes, random.PRNGKey(0))\n",
    "\n",
    "window = random.normal(random.PRNGKey(0), (7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-19 14:13:44.558782: W external/tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.98GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-19 14:13:46.291657: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=0,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:46.292633: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.001081868s\n",
      "Trying algorithm eng28{k2=0,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:47.292808: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:47.427904: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.135205557s\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:49.254651: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng30{k2=0,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:49.470998: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.216426846s\n",
      "Trying algorithm eng30{k2=0,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:50.933638: W external/tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.98GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-10-19 14:13:53.659634: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=0,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:56.908006: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 4.248496521s\n",
      "Trying algorithm eng28{k2=0,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:57.908323: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng1{k2=2,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:13:59.647382: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.739298274s\n",
      "Trying algorithm eng1{k2=2,k3=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:00.647628: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng30{k2=1,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:00.989794: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.342320289s\n",
      "Trying algorithm eng30{k2=1,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:02.547156: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng30{k2=0,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:03.018094: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.471066953s\n",
      "Trying algorithm eng30{k2=0,k4=3,k5=1,k6=0,k7=0} for conv (f32[112800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[112800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:07.963048: E external/xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng28{k2=0,k3=0} for conv (f32[18800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[18800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n",
      "2023-10-19 14:14:08.035627: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.072713026s\n",
      "Trying algorithm eng28{k2=0,k3=0} for conv (f32[18800,1,22,22]{3,2,1,0}, u8[0]{0}) custom-call(f32[18800,1,28,28]{3,2,1,0}, f32[1,1,7,7]{3,2,1,0}), window={size=7x7}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 in 8.41 sec\n",
      "Training set accuracy 0.6390248537063599\n",
      "Test set accuracy 0.6165957450866699\n",
      "Epoch 1 in 6.52 sec\n",
      "Training set accuracy 0.7133333683013916\n",
      "Test set accuracy 0.6851063966751099\n",
      "Epoch 2 in 6.48 sec\n",
      "Training set accuracy 0.7521986365318298\n",
      "Test set accuracy 0.7189361453056335\n",
      "Epoch 3 in 5.92 sec\n",
      "Training set accuracy 0.777216374874115\n",
      "Test set accuracy 0.7423403859138489\n",
      "Epoch 4 in 5.97 sec\n",
      "Training set accuracy 0.7957181334495544\n",
      "Test set accuracy 0.7555850744247437\n",
      "Epoch 5 in 6.19 sec\n",
      "Training set accuracy 0.8101241588592529\n",
      "Test set accuracy 0.7672340273857117\n",
      "Epoch 6 in 6.36 sec\n",
      "Training set accuracy 0.8209840655326843\n",
      "Test set accuracy 0.774893581867218\n",
      "Epoch 7 in 6.29 sec\n",
      "Training set accuracy 0.8306560516357422\n",
      "Test set accuracy 0.780904233455658\n",
      "Epoch 8 in 6.17 sec\n",
      "Training set accuracy 0.838129460811615\n",
      "Test set accuracy 0.7847340106964111\n",
      "Epoch 9 in 6.17 sec\n",
      "Training set accuracy 0.8444504141807556\n",
      "Test set accuracy 0.787872314453125\n",
      "Epoch 10 in 6.15 sec\n",
      "Training set accuracy 0.8509929776191711\n",
      "Test set accuracy 0.7918617129325867\n",
      "Epoch 11 in 6.12 sec\n",
      "Training set accuracy 0.8563564419746399\n",
      "Test set accuracy 0.7941489219665527\n",
      "Epoch 12 in 6.26 sec\n",
      "Training set accuracy 0.8610727190971375\n",
      "Test set accuracy 0.7959042191505432\n",
      "Epoch 13 in 6.28 sec\n",
      "Training set accuracy 0.8658156394958496\n",
      "Test set accuracy 0.7982446551322937\n",
      "Epoch 14 in 6.19 sec\n",
      "Training set accuracy 0.8701241612434387\n",
      "Test set accuracy 0.8000531792640686\n",
      "Epoch 15 in 6.35 sec\n",
      "Training set accuracy 0.873971700668335\n",
      "Test set accuracy 0.8013829588890076\n",
      "Epoch 16 in 6.45 sec\n",
      "Training set accuracy 0.8773138523101807\n",
      "Test set accuracy 0.8025000095367432\n",
      "Epoch 17 in 6.08 sec\n",
      "Training set accuracy 0.8805851340293884\n",
      "Test set accuracy 0.804202139377594\n",
      "Epoch 18 in 6.06 sec\n",
      "Training set accuracy 0.8836259245872498\n",
      "Test set accuracy 0.8050000071525574\n",
      "Epoch 19 in 6.08 sec\n",
      "Training set accuracy 0.8868440389633179\n",
      "Test set accuracy 0.8057978749275208\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  start_time = time.time()\n",
    "  for x, y in training_generator:\n",
    "    y = one_hot(y, n_targets)\n",
    "    window, params = update(params, window, x, y)\n",
    "  epoch_time = time.time() - start_time\n",
    "\n",
    "  train_acc = accuracy(params, window, train_images, train_labels)\n",
    "  test_acc = accuracy(params, window, test_images, test_labels)\n",
    "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
    "  print(\"Training set accuracy {}\".format(train_acc))\n",
    "  print(\"Test set accuracy {}\".format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
